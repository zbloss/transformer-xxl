{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer, BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will use Chapter's from Mary Shelly's Frankenstein as example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am by birth a Genevese, and my family is one of the most distinguished of that republic. My ancestors had been for many years counsellors and syndics, and my father had filled several public situations with honour and reputation. He was respected by all who knew him for his integrity and indefatigable attention to public business. He passed his younger days perpetually occupied by the affairs of his country; a variety of circumstances had prevented his marrying early, nor was it until the decline of life that he became a husband and the father of a family. As the circumstances of his marriage illustrate his character, I cannot refrain from relating them. One of his most intimate friends was a merchant who, from a flourishing state, fell, through numerous mischances, into poverty. This man, whose name was Beaufort, was of a proud and unbending disposition and could not bear to live in poverty and oblivion in the same country where he had formerly been distinguished for his rank and ma'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/frankenstein/chapter_1.txt', 'rb') as file:\n",
    "    ch1 = file.read().decode()\n",
    "    file.close()\n",
    "\n",
    "with open('../data/frankenstein/chapter_2.txt', 'rb') as file:\n",
    "    ch2 = file.read().decode()\n",
    "    file.close()\n",
    "\n",
    "ch1[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0102 21:27:27.861990  7748 tokenization_utils.py:380] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Dimension: 512\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "print(f'Model Input Dimension: {tokenizer.max_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing using BertTokenizer provided by [HuggingFace BertTokenizer](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer)\n",
    "\n",
    "The text in Chapter 1 contains 2,195 tokens total.\n",
    "The text in Chapter 2 contains 2,782 tokens total. \n",
    "\n",
    "We now want to find the closest, largest, multiple of 512 (the expected input dimension of the Bert Model).\n",
    "This number divided by 512 will give us the `m` dimension of our soon to be `m`x`512` matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0102 21:30:47.402800  7748 tokenization_utils.py:953] Token indices sequence length is longer than the specified maximum sequence length for this model (2193 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0102 21:30:47.435803  7748 tokenization_utils.py:953] Token indices sequence length is longer than the specified maximum sequence length for this model (2780 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1 contains 2195 tokens\n",
      "Chapter 2 contains 2782 tokens\n"
     ]
    }
   ],
   "source": [
    "seqlen = tokenizer.max_len\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "tok_ch1 = tokenizer.encode(ch1)\n",
    "tok_ch2 = tokenizer.encode(ch2)\n",
    "\n",
    "print(f'Chapter 1 contains {len(tok_ch1)} tokens')\n",
    "print(f'Chapter 2 contains {len(tok_ch2)} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 6\n"
     ]
    }
   ],
   "source": [
    "if len(tok_ch1) > len(tok_ch2):\n",
    "    m = (len(tok_ch1) // seqlen) + 1\n",
    "else:\n",
    "    m = (len(tok_ch2) // seqlen) + 1\n",
    "print(f'm = {m}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D-Padding\n",
    "\n",
    "We now need to pad our n-sequence to m*512 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_ch1.shape: (3072,)\n",
      "tok_ch2.shape: (3072,)\n"
     ]
    }
   ],
   "source": [
    "tok_ch1 = np.array(tok_ch1)\n",
    "tok_ch2 = np.array(tok_ch2)\n",
    "\n",
    "print(f'tok_ch1.shape: {tok_ch1.shape}')\n",
    "print(f'tok_ch2.shape: {tok_ch2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_2d(arr: np.array, \n",
    "               pad_token_id: int, \n",
    "               seqlen: int,\n",
    "               seqdim: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Pads a 1D array to the proper length, then reshapes and returns\n",
    "    a 2D array\n",
    "    \n",
    "    :param arr: the list to be padded.\n",
    "    :param pad_token_id: the token id to be used for padding.\n",
    "    :param seqlen: the length of each row in the desired matrix.\n",
    "    :param seqdim: the number of rows in the desired matrix.\n",
    "    \"\"\"\n",
    "    if len(arr) < seqlen * seqdim:\n",
    "        to_pad = seqlen * seqdim - len(arr)\n",
    "        arr += [pad_token_id] * to_pad\n",
    "        \n",
    "    arr = np.array(arr).reshape((seqdim, seqlen))\n",
    "    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_ch1.shape: (6, 512)\n",
      "tok_ch2.shape: (6, 512)\n"
     ]
    }
   ],
   "source": [
    "tok_ch1 = padding_2d(tok_ch1, pad_token_id, seqlen, m)\n",
    "tok_ch2 = padding_2d(tok_ch2, pad_token_id, seqlen, m)\n",
    "\n",
    "print(f'tok_ch1.shape: {tok_ch1.shape}')\n",
    "print(f'tok_ch2.shape: {tok_ch2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor-Shape\n",
    "\n",
    "Treating the tensor as a:\n",
    "* batch_size = 1\n",
    "* channels = seqdim\n",
    "* height = 1\n",
    "* width = seqlen\n",
    "\n",
    "Essentially treating each of the `seqdim` rows as a channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ten_ch1 = torch.tensor(tok_ch1, dtype=torch.float)\n",
    "ten_ch1 = ten_ch1.view(1, tok_ch1.shape[0], 1, tok_ch1.shape[1])\n",
    "\n",
    "ten_ch2 = torch.tensor(tok_ch2, dtype=torch.float)\n",
    "ten_ch2 = ten_ch1.view(1, tok_ch2.shape[0], 1, tok_ch2.shape[1])\n",
    "\n",
    "model_layers = [\n",
    "    nn.Conv2d(in_channels=ten_ch1.shape[1], \n",
    "          out_channels=1,\n",
    "          kernel_size=1),\n",
    "    nn.LayerNorm((1,512)),\n",
    "    nn.ReLU(inplace=True)\n",
    "]\n",
    "\n",
    "model = nn.Sequential(*model_layers)\n",
    "\n",
    "x = model(ten_ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([1, 6, 1, 512])\n",
      "Output tensor shape: torch.Size([1, 1, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(f'Original tensor shape: {ten_ch1.shape}')\n",
    "print(f'Output tensor shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0102 22:12:20.814961  7748 configuration_utils.py:157] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I0102 22:12:20.820956  7748 configuration_utils.py:174] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0102 22:12:21.025045  7748 modeling_utils.py:393] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel2D(nn.Module):\n",
    "\n",
    "    def __init__(self, seqdim, seqlen, batch_size):\n",
    "        super(BertModel2D, self).__init__()\n",
    "        \n",
    "        self.seqdim = seqdim\n",
    "        self.seqlen = seqlen\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(seqdim, 1, 1)\n",
    "        self.layer_norm = nn.LayerNorm((1, seqlen))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(self.batch_size, seqlen).long()\n",
    "        x = self.bert(input_ids = x, attention_mask = mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0102 22:22:46.741231  7748 configuration_utils.py:157] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I0102 22:22:46.744235  7748 configuration_utils.py:174] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0102 22:22:46.955271  7748 modeling_utils.py:393] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
     ]
    }
   ],
   "source": [
    "model = BertModel2D(seqdim=6, seqlen=512, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.where(np.tril(tok_ch1), 1, 0)\n",
    "mask = torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "hidden_states, output = model(ten_ch1)  #, mask)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
