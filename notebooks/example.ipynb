{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 08:11:22.269854 13188 file_utils.py:33] TensorFlow version 2.0.0 available.\n",
      "I0103 08:11:22.273853 13188 file_utils.py:40] PyTorch version 1.3.1 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer, BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We will use Chapter's from Mary Shelly's Frankenstein as example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am by birth a Genevese, and my family is one of the most distinguished of that republic. My ancestors had been for many years counsellors and syndics, and my father had filled several public situations with honour and reputation. He was respected by all who knew him for his integrity and indefatigable attention to public business. He passed his younger days perpetually occupied by the affairs of his country; a variety of circumstances had prevented his marrying early, nor was it until the decline of life that he became a husband and the father of a family. As the circumstances of his marriage illustrate his character, I cannot refrain from relating them. One of his most intimate friends was a merchant who, from a flourishing state, fell, through numerous mischances, into poverty. This man, whose name was Beaufort, was of a proud and unbending disposition and could not bear to live in poverty and oblivion in the same country where he had formerly been distinguished for his rank and ma'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/frankenstein/chapter_1.txt', 'rb') as file:\n",
    "    ch1 = file.read().decode()\n",
    "    file.close()\n",
    "\n",
    "with open('../data/frankenstein/chapter_2.txt', 'rb') as file:\n",
    "    ch2 = file.read().decode()\n",
    "    file.close()\n",
    "\n",
    "ch1[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 08:11:24.088873 13188 tokenization_utils.py:380] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Dimension: 512\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "print(f'Model Input Dimension: {tokenizer.max_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing using BertTokenizer provided by [HuggingFace BertTokenizer](https://huggingface.co/transformers/model_doc/bert.html#berttokenizer)\n",
    "\n",
    "The text in Chapter 1 contains 2,195 tokens total.\n",
    "The text in Chapter 2 contains 2,782 tokens total. \n",
    "\n",
    "We now want to find the closest, largest, multiple of 512 (the expected input dimension of the Bert Model).\n",
    "This number divided by 512 will give us the `m` dimension of our soon to be `m`x`512` matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0103 08:14:35.971841 13188 tokenization_utils.py:953] Token indices sequence length is longer than the specified maximum sequence length for this model (2193 > 512). Running this sequence through the model will result in indexing errors\n",
      "W0103 08:14:36.004843 13188 tokenization_utils.py:953] Token indices sequence length is longer than the specified maximum sequence length for this model (2780 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1 contains 2195 tokens\n",
      "Chapter 2 contains 2782 tokens\n"
     ]
    }
   ],
   "source": [
    "seqlen = tokenizer.max_len\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "tok_ch1 = tokenizer.encode(ch1)\n",
    "tok_ch2 = tokenizer.encode(ch2)\n",
    "\n",
    "print(f'Chapter 1 contains {len(tok_ch1)} tokens')\n",
    "print(f'Chapter 2 contains {len(tok_ch2)} tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 6\n"
     ]
    }
   ],
   "source": [
    "if len(tok_ch1) > len(tok_ch2):\n",
    "    m = (len(tok_ch1) // seqlen) + 1\n",
    "else:\n",
    "    m = (len(tok_ch2) // seqlen) + 1\n",
    "print(f'm = {m}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D-Padding\n",
    "\n",
    "We now need to pad our n-sequence to m*512 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_ch1.shape: (2195,)\n",
      "tok_ch2.shape: (2782,)\n"
     ]
    }
   ],
   "source": [
    "tok_ch1 = np.array(tok_ch1)\n",
    "tok_ch2 = np.array(tok_ch2)\n",
    "\n",
    "print(f'tok_ch1.shape: {tok_ch1.shape}')\n",
    "print(f'tok_ch2.shape: {tok_ch2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_2d(arr: np.array, \n",
    "               pad_token_id: int, \n",
    "               seqlen: int,\n",
    "               seqdim: int) -> np.array:\n",
    "    \"\"\"\n",
    "    Pads a 1D array to the proper length, then reshapes and returns\n",
    "    a 2D array\n",
    "    \n",
    "    :param arr: the list to be padded.\n",
    "    :param pad_token_id: the token id to be used for padding.\n",
    "    :param seqlen: the length of each row in the desired matrix.\n",
    "    :param seqdim: the number of rows in the desired matrix.\n",
    "    \"\"\"\n",
    "    if len(arr) < seqlen * seqdim:\n",
    "        to_pad = seqlen * seqdim - len(arr)\n",
    "        arr = np.append(arr,([pad_token_id] * to_pad))\n",
    "        \n",
    "    arr = np.array(arr).reshape((seqdim, 1, seqlen))\n",
    "    \n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_ch1.shape: (6, 1, 512)\n",
      "tok_ch2.shape: (6, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "tok_ch1 = padding_2d(tok_ch1, pad_token_id, seqlen, m)\n",
    "tok_ch2 = padding_2d(tok_ch2, pad_token_id, seqlen, m)\n",
    "\n",
    "print(f'tok_ch1.shape: {tok_ch1.shape}')\n",
    "print(f'tok_ch2.shape: {tok_ch2.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor-Shape\n",
    "\n",
    "Treating the tensor as a:\n",
    "* batch_size = 1\n",
    "* channels = seqdim\n",
    "* height = 1\n",
    "* width = seqlen\n",
    "\n",
    "Essentially treating each of the `seqdim` rows as a channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ten_ch1 = torch.tensor(tok_ch1, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "ten_ch2 = torch.tensor(tok_ch2, dtype=torch.float).unsqueeze(0)\n",
    "\n",
    "model_layers = [\n",
    "    nn.Conv2d(in_channels=ten_ch1.shape[1], \n",
    "          out_channels=1,\n",
    "          kernel_size=1),\n",
    "    nn.LayerNorm((1,512)),\n",
    "    nn.ReLU(inplace=True)\n",
    "]\n",
    "\n",
    "model = nn.Sequential(*model_layers)\n",
    "\n",
    "x = model(ten_ch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: torch.Size([1, 6, 1, 512])\n",
      "Output tensor shape: torch.Size([1, 1, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "print(f'Original tensor shape: {ten_ch1.shape}')\n",
    "print(f'Output tensor shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 08:15:04.032249 13188 configuration_utils.py:157] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I0103 08:15:04.038210 13188 configuration_utils.py:174] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0103 08:15:04.240507 13188 modeling_utils.py:393] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel2D(nn.Module):\n",
    "\n",
    "    def __init__(self, seqdim, seqlen, batch_size):\n",
    "        super(BertModel2D, self).__init__()\n",
    "        \n",
    "        self.seqdim = seqdim\n",
    "        self.seqlen = seqlen\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(seqdim, 1, 1)\n",
    "        self.layer_norm = nn.LayerNorm((1, seqlen))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.relu(x)\n",
    "        x = x.view(self.batch_size, seqlen).long()\n",
    "        x = self.bert(input_ids = x, attention_mask = mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0103 08:15:06.405121 13188 configuration_utils.py:157] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "I0103 08:15:06.408123 13188 configuration_utils.py:174] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0103 08:15:06.614080 13188 modeling_utils.py:393] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\altoz\\.cache\\torch\\transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n"
     ]
    }
   ],
   "source": [
    "model = BertModel2D(seqdim=6, seqlen=512, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.where(np.tril(tok_ch1), 1, 0)\n",
    "mask = torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "hidden_states, output = model(ten_ch1)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
